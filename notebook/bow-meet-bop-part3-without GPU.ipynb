{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13425389,"sourceType":"datasetVersion","datasetId":8521174},{"sourceId":13425536,"sourceType":"datasetVersion","datasetId":8521280},{"sourceId":13431583,"sourceType":"datasetVersion","datasetId":8525087}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from gensim.models import Word2Vec\nfrom sklearn.cluster import KMeans\nimport time\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\n\nfrom cuml.cluster import KMeans as cuKMeans\nfrom cuml.ensemble import RandomForestClassifier as cuRF\n\nimport sys\nsys.path.append('/kaggle/input/kaggleword2vecutility/')\nfrom KaggleWord2VecUtility import KaggleWord2VecUtility\n\ndef create_bag_of_centroids(wordlist, word_centroid_map):\n    num_centroids = max(word_centroid_map.values()) + 1\n    bag_of_centroids = np.zeros(num_centroids, dtype=\"float32\")\n\n    for word in wordlist:\n        if word in word_centroid_map:\n            index = word_centroid_map[word]\n            bag_of_centroids[index] += 1\n\n    return bag_of_centroids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T09:14:35.545760Z","iopub.execute_input":"2025-10-19T09:14:35.546019Z","iopub.status.idle":"2025-10-19T09:14:55.371553Z","shell.execute_reply.started":"2025-10-19T09:14:35.545994Z","shell.execute_reply":"2025-10-19T09:14:55.370968Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"if __name__ == '__main__':\n    model = Word2Vec.load('/kaggle/input/300features-40minwords-10context/300features_40minwords_10context')\n\n    start = time.time()\n\n    word_vectors = model.wv.vectors\n    num_clusters = word_vectors.shape[0] // 5  # 整除\n\n    print(\"Running K means\")\n    kmeans_clustering = KMeans(n_clusters=num_clusters, n_init=10, random_state=42)\n    idx = kmeans_clustering.fit_predict(word_vectors)\n\n    end = time.time()\n    elapsed = end - start\n    print(\"Time taken for K Means clustering:\", elapsed, \"seconds.\")\n\n    word_centroid_map = dict(zip(model.wv.index_to_key, idx))\n\n    for cluster in range(10):\n        print(\"\\nCluster %d\" % cluster)\n        words = [word for word, cluster_idx in word_centroid_map.items() if cluster_idx == cluster]\n        print(words)\n\n    train = pd.read_csv('/kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv/labeledTrainData.tsv',\n                        header=0, delimiter=\"\\t\", quoting=3)\n    test = pd.read_csv('/kaggle/input/word2vec-nlp-tutorial/testData.tsv/testData.tsv',\n                       header=0, delimiter=\"\\t\", quoting=3)\n\n    print(\"Cleaning training reviews\")\n    clean_train_reviews = [KaggleWord2VecUtility.review_to_wordlist(review, remove_stopwords=True)\n                           for review in train[\"review\"]]\n\n    print(\"Cleaning test reviews\")\n    clean_test_reviews = [KaggleWord2VecUtility.review_to_wordlist(review, remove_stopwords=True)\n                          for review in test[\"review\"]]\n\n    train_centroids = np.zeros((train[\"review\"].size, num_clusters), dtype=\"float32\")\n    for i, review in enumerate(clean_train_reviews):\n        train_centroids[i] = create_bag_of_centroids(review, word_centroid_map)\n\n    test_centroids = np.zeros((test[\"review\"].size, num_clusters), dtype=\"float32\")\n    for i, review in enumerate(clean_test_reviews):\n        test_centroids[i] = create_bag_of_centroids(review, word_centroid_map)\n\n    forest = RandomForestClassifier(n_estimators=100, random_state=42)\n    print(\"Fitting a random forest to labeled training data...\")\n    forest.fit(train_centroids, train[\"sentiment\"])\n    result = forest.predict(test_centroids)\n\n    output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": result})\n    output.to_csv(\"/kaggle/working/BagOfCentroids.csv\", index=False, quoting=3)\n    print(\"Wrote /kaggle/working/BagOfCentroids.csv\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-19T09:14:55.372830Z","iopub.execute_input":"2025-10-19T09:14:55.373360Z","iopub.status.idle":"2025-10-19T09:26:19.212111Z","shell.execute_reply.started":"2025-10-19T09:14:55.373341Z","shell.execute_reply":"2025-10-19T09:26:19.211291Z"}},"outputs":[{"name":"stdout","text":"Running K means\nTime taken for K Means clustering: 574.2157273292542 seconds.\n\nCluster 0\n['whereas', 'glory', 'undoubtedly', 'alongside', 'saga', 'imitation', 'arguably', 'outing', 'contribution', 'demille', 'comeback', 'foremost', 'pairing', 'blockbusters', 'greats', 'biopic', 'forties', 'filmography', 'earliest', 'creations', 'romances', 'nineties', 'twenties', 'vaudeville', 'achievements', 'warners', 'icons', 'output', 'talkie', 'offerings', 'schindler', 'talkies', 'twentieth', 'seller', 'successes', 'heyday', 'operas', 'disappointments', 'viii', 'ealing', 'noirs', 'outings', 'silents', 'swashbuckler', 'singin', 'melodramas', 'collaborations']\n\nCluster 1\n['directly', 'blank', 'visible', 'randomly', 'boom', 'rear']\n\nCluster 2\n['idiots', 'losers', 'fools', 'morons']\n\nCluster 3\n['dates', 'cons', 'rivals', 'geeks', 'professionals', 'pros', 'queens', 'arguing', 'competing', 'participants', 'somethings', 'clowns', 'amateurs', 'troupe', 'unknowns', 'sessions', 'giants', 'misfits', 'premises', 'bickering', 'nerds', 'hosts', 'consisting', 'consisted', 'assorted', 'jerks', 'geniuses', 'youths', 'hacks', 'meetings', 'pranks', 'bastards', 'lords', 'comprised', 'patrons', 'surfers', 'hillbillies', 'pets', 'hookers', 'mismatched', 'fold', 'weddings', 'freshman', 'beauties', 'gals', 'newcomers', 'interludes', 'housewives', 'roommates', 'heroines', 'marriages', 'whores', 'rag', 'treasures', 'candidates', 'attractions', 'opposites', 'strippers', 'psychos', 'bums', 'innocents', 'brats', 'misadventures', 'sidekicks', 'duds', 'cheerleaders', 'wrestlers', 'jocks', 'quartet', 'barrels', 'aunts', 'pioneers', 'crews', 'lads', 'travelers', 'nubile', 'cutouts', 'moms', 'acquaintances', 'drunks', 'goodies', 'factions', 'adversaries', 'blondes', 'knit', 'musketeers', 'blacktop', 'slackers', 'standouts', 'chores', 'orphans', 'designers', 'snobs', 'competitors', 'heavies', 'pimps', 'bimbos', 'heros', 'incarnations', 'clans', 'weirdos', 'superstars', 'entertainers', 'exercises', 'pairs', 'athletes', 'assistants', 'painters']\n\nCluster 4\n['stylish', 'imaginative', 'innovative', 'inventive']\n\nCluster 5\n['disease', 'illness', 'nightmares', 'cancer', 'severe', 'visions', 'surgery', 'breakdown', 'habit', 'disorder', 'trauma', 'hallucinations']\n\nCluster 6\n['spare']\n\nCluster 7\n['jeff', 'patrick', 'jon']\n\nCluster 8\n['cave', 'lab', 'plant']\n\nCluster 9\n['performer', 'musician', 'ol', 'pianist', 'loretta', 'gig', 'natured', 'lad', 'drifter']\nCleaning training reviews\nCleaning test reviews\nFitting a random forest to labeled training data...\nWrote /kaggle/working/BagOfCentroids.csv\n","output_type":"stream"}],"execution_count":2}]}