{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13425389,"sourceType":"datasetVersion","datasetId":8521174},{"sourceId":13425536,"sourceType":"datasetVersion","datasetId":8521280},{"sourceId":13431583,"sourceType":"datasetVersion","datasetId":8525087}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from gensim.models import Word2Vec\nfrom sklearn.cluster import KMeans\nimport time\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\n\nfrom cuml.cluster import KMeans as cuKMeans\nfrom cuml.ensemble import RandomForestClassifier as cuRF\n\nimport sys\nsys.path.append('/kaggle/input/kaggleword2vecutility/')\nfrom KaggleWord2VecUtility import KaggleWord2VecUtility\n\ndef create_bag_of_centroids(wordlist, word_centroid_map):\n    num_centroids = max(word_centroid_map.values()) + 1\n    bag_of_centroids = np.zeros(num_centroids, dtype=\"float32\")\n\n    for word in wordlist:\n        if word in word_centroid_map:\n            index = word_centroid_map[word]\n            bag_of_centroids[index] += 1\n\n    return bag_of_centroids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T09:58:21.576845Z","iopub.execute_input":"2025-10-19T09:58:21.577077Z","iopub.status.idle":"2025-10-19T09:58:21.582396Z","shell.execute_reply.started":"2025-10-19T09:58:21.577057Z","shell.execute_reply":"2025-10-19T09:58:21.581659Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"if __name__ == '__main__':\n    model = Word2Vec.load('/kaggle/input/300features-40minwords-10context/300features_40minwords_10context')\n\n    start = time.time()\n\n    word_vectors = model.wv.vectors\n    num_clusters = word_vectors.shape[0] // 5  # 整除\n\n    print(\"Running K means\")\n    kmeans_clustering = cuKMeans(n_clusters=num_clusters, n_init=10, random_state=42)\n    idx = kmeans_clustering.fit_predict(word_vectors)\n    end = time.time()\n    elapsed = end - start\n    print(\"Time taken for K Means clustering:\", elapsed, \"seconds.\")\n\n    word_centroid_map = dict(zip(model.wv.index_to_key, idx))\n\n    for cluster in range(10):\n        print(\"\\nCluster %d\" % cluster)\n        words = [word for word, cluster_idx in word_centroid_map.items() if cluster_idx == cluster]\n        print(words)\n\n    train = pd.read_csv('/kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv/labeledTrainData.tsv',\n                        header=0, delimiter=\"\\t\", quoting=3)\n    test = pd.read_csv('/kaggle/input/word2vec-nlp-tutorial/testData.tsv/testData.tsv',\n                       header=0, delimiter=\"\\t\", quoting=3)\n\n    print(\"Cleaning training reviews\")\n    clean_train_reviews = [KaggleWord2VecUtility.review_to_wordlist(review, remove_stopwords=True)\n                           for review in train[\"review\"]]\n\n    print(\"Cleaning test reviews\")\n    clean_test_reviews = [KaggleWord2VecUtility.review_to_wordlist(review, remove_stopwords=True)\n                          for review in test[\"review\"]]\n\n    train_centroids = np.zeros((train[\"review\"].size, num_clusters), dtype=\"float32\")\n    for i, review in enumerate(clean_train_reviews):\n        train_centroids[i] = create_bag_of_centroids(review, word_centroid_map)\n\n    test_centroids = np.zeros((test[\"review\"].size, num_clusters), dtype=\"float32\")\n    for i, review in enumerate(clean_test_reviews):\n        test_centroids[i] = create_bag_of_centroids(review, word_centroid_map)\n\n    print(\"Fitting a random forest to labeled training data...\")\n    forest = cuRF(n_estimators=100, random_state=42)\n    forest.fit(train_centroids, train[\"sentiment\"])\n    result = forest.predict(test_centroids)\n\n    output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": result})\n    output.to_csv(\"/kaggle/working/BagOfCentroids.csv\", index=False, quoting=3)\n    print(\"Wrote /kaggle/working/BagOfCentroids.csv\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-19T09:58:21.583037Z","iopub.execute_input":"2025-10-19T09:58:21.583248Z"}},"outputs":[{"name":"stdout","text":"Running K means\nTime taken for K Means clustering: 23.388715028762817 seconds.\n\nCluster 0\n['spirit']\n\nCluster 1\n['subsequent', 'fatal', 'resulting', 'ensues', 'courtroom', 'charged', 'abruptly', 'disastrous', 'rapidly', 'shifts', 'devastating', 'neatly', 'witnessing', 'complications', 'grisly', 'traumatic', 'ensue', 'arise', 'occurring', 'culminating', 'downward', 'culminates']\n\nCluster 2\n['host', 'buster', 'seinfeld', 'sparks', 'chops', 'springer', 'irwin', 'leno', 'bruckheimer']\n\nCluster 3\n['intellectual', 'ultra', 'object', 'achievement', 'argument', 'alternative', 'agenda', 'educational', 'adolescent', 'objective', 'abortion', 'indication', 'examination', 'array', 'allegory', 'exaggeration', 'abundance', 'ounce', 'assortment']\n\nCluster 4\n['fictional', 'arc', 'outline', 'progression', 'arcs']\n\nCluster 5\n['horrors', 'conditions', 'theories', 'camps', 'atrocities']\n\nCluster 6\n['er', 'troy', 'ash', 'reggie', 'homer', 'fry', 'genie', 'awry', 'mulder', 'reaper', 'arnie', 'kenny', 'grinch', 'inuyasha', 'jafar', 'scully', 'teddy', 'hes', 'astro', 'gator', 'herbie', 'timon', 'nemo', 'shaggy', 'smallville', 'wan', 'blackadder', 'elmer', 'yor', 'futurama', 'diesel', 'pinhead', 'martian', 'carlito', 'vin', 'yoda', 'goku', 'duane', 'anakin', 'iago', 'chucky', 'po', 'garth', 'dino', 'zack', 'banner', 'daredevil', 'suspiciously', 'leprechaun', 'airwolf', 'hutch', 'jericho', 'wraith', 'wwf', 'sesame', 'papa', 'starsky', 'scrappy', 'cannonball', 'luthor', 'pumbaa', 'squall', 'dexter', 'frodo', 'cartman', 'bots', 'clause', 'pumpkinhead', 'voorhees', 'michaels', 'elmo', 'pluto', 'tong', 'elwood', 'simba', 'spongebob', 'aquaman', 'gilligan', 'scotty', 'conquers', 'statham', 'squirrel', 'jabba', 'rimmer', 'thundercats', 'ripley', 'booker', 'reb', 'brock', 'friar', 'twister', 'obi', 'goblin', 'leia', 'darkwing']\n\nCluster 7\n['charismatic', 'miscast', 'gifted']\n\nCluster 8\n['repeatedly', 'randomly', 'nuts', 'hungry', 'bath', 'surgery', 'babies', 'wounds', 'poison', 'feeding', 'filthy', 'stabbed', 'cells', 'melting', 'penis', 'ritual', 'exploding', 'severed', 'heroin', 'trigger', 'cocaine', 'sucking', 'bleeding', 'stabbing', 'cigarettes', 'stoned', 'drowning', 'stripped', 'unconscious', 'goat', 'crushed', 'hairy', 'worm', 'raping', 'knives', 'rapes', 'worms', 'torturing', 'stabs', 'dope', 'smashed', 'violently', 'pills', 'punching', 'trunk', 'whipped', 'rotting', 'bra', 'someones', 'busted', 'gunshot', 'organs', 'decapitated', 'needle', 'slashing', 'decapitation', 'grenade', 'masturbating', 'slashed', 'machete', 'sliced', 'slit', 'intestines', 'impaled', 'chickens', 'maggots']\n\nCluster 9\n['rough', 'neat', 'slight', 'mild', 'broad', 'minimal', 'smooth', 'slick', 'frequent', 'consistent', 'trademark', 'minimum', 'straightforward', 'static', 'shaky', 'steady', 'choppy', 'jarring', 'flashy', 'noticeable', 'stylized', 'pedestrian', 'deliberate', 'rapid', 'fluid', 'snappy', 'sparse']\nCleaning training reviews\nCleaning test reviews\n","output_type":"stream"}],"execution_count":null}]}