{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3971,"databundleVersionId":32703,"sourceType":"competition"},{"sourceId":13425389,"sourceType":"datasetVersion","datasetId":8521174},{"sourceId":13425536,"sourceType":"datasetVersion","datasetId":8521280}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nimport sys\nsys.path.append('/kaggle/input/kaggleword2vecutility')\nfrom KaggleWord2VecUtility import KaggleWord2VecUtility\nimport pandas as pd\nimport numpy as np\n\nif __name__ == '__main__':\n    train = pd.read_csv(\n        '/kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv/labeledTrainData.tsv',\n        header=0, delimiter=\"\\t\", quoting=3\n    )\n    test = pd.read_csv(\n        '/kaggle/input/word2vec-nlp-tutorial/testData.tsv/testData.tsv',\n        header=0, delimiter=\"\\t\", quoting=3\n    )\n\n    print(train.shape)\n    print(train.columns.values)\n    \n    \n    print('The first review is:')\n    print(train[\"review\"][0])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-19T04:49:20.787511Z","iopub.execute_input":"2025-10-19T04:49:20.788316Z","iopub.status.idle":"2025-10-19T04:49:21.552346Z","shell.execute_reply.started":"2025-10-19T04:49:20.788292Z","shell.execute_reply":"2025-10-19T04:49:21.551572Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    print('Download text data sets. If you already have NLTK datasets downloaded, just close the Python download window...')\n    # nltk.download()  # 若需要可启用\n\n    # 清洗训练集\n    clean_train_reviews = []\n    print(\"Cleaning and parsing the training set movie reviews...\\n\")\n    for i in range(0, len(train[\"review\"])):\n        clean_train_reviews.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(train[\"review\"][i], True)))\n\n    # 创建词袋模型\n    print(\"Creating the bag of words...\\n\")\n    vectorizer = CountVectorizer(\n        analyzer=\"word\",\n        tokenizer=None,\n        preprocessor=None,\n        stop_words=None,\n        max_features=5000\n    )\n\n    train_data_features = vectorizer.fit_transform(clean_train_reviews)\n    np.asarray(train_data_features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T04:49:21.553745Z","iopub.execute_input":"2025-10-19T04:49:21.553977Z","iopub.status.idle":"2025-10-19T04:49:35.991329Z","shell.execute_reply.started":"2025-10-19T04:49:21.553959Z","shell.execute_reply":"2025-10-19T04:49:35.990496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    # 训练随机森林\n    print(\"Training the random forest (this may take a while)...\")\n    forest = RandomForestClassifier(n_estimators=100, random_state=42)\n    forest.fit(train_data_features, train[\"sentiment\"])\n\n    # 清洗测试集\n    clean_test_reviews = []\n    print(\"Cleaning and parsing the test set movie reviews...\\n\")\n    for i in range(0, len(test[\"review\"])):\n        clean_test_reviews.append(\n            \" \".join(KaggleWord2VecUtility.review_to_wordlist(test[\"review\"][i], True))\n        )\n\n    test_data_features = vectorizer.transform(clean_test_reviews)\n    np.asarray(test_data_features)\n\n    # 预测\n    print(\"Predicting test labels...\\n\")\n    result = forest.predict(test_data_features)\n\n    # 输出结果\n    output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": result})\n    output_path = '/kaggle/working/Bag_of_Words_model.csv'\n    output.to_csv(output_path, index=False, quoting=3)\n    print(f\"Wrote results to {output_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T04:49:35.992251Z","iopub.execute_input":"2025-10-19T04:49:35.992464Z","iopub.status.idle":"2025-10-19T04:50:43.772914Z","shell.execute_reply.started":"2025-10-19T04:49:35.992443Z","shell.execute_reply":"2025-10-19T04:50:43.772106Z"}},"outputs":[],"execution_count":null}]}